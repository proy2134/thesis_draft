%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% conclusion.tex:
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Conclusion and Future Work}
\label{conclusion_chapter}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
The primary objective of this dissertation was to develop practical solutions for yield mapping in specialty farms. To accomplish this target, we first presented multiple techniques for fruit detection, counting, recovering underlying scene geometry and merging reconstructions from both sides of a tree row. We integrated these solutions in a modular way to create a complete yield mapping system solely based on visual data. Second, we studied active perception in the context of accurate fruit counting in more general settings. Finally, we studied how to leverage existing image to image translation techniques for realistic synthetic data generation. The techniques developed are useful for many other applications domains beyond fruit detection and counting such as autonomous driving, image stylization, and object transfiguration.

In this chapter, we summarize our contributions, discuss some follow-up research questions and open problems.

\section{Contributions and Open Problems}

In Chapter~\ref{chapter:detection}, we presented two methods for fruit detection - a classical approach based on semi-supervised clustering and a deep learning approach based on a pixel-wise segmentation network. The clustering approach essentially performs a specialized color-based segmentation. Therefore, the method can detect any object distinguishable by color. The approach suffers when color information alone is not sufficient. An immediate research question is how to extend the framework for with features other than color. The deep learning approaches provide a solution to this problem in the sense that they automate the process of learning features given a sufficient amount of training data. Detection techniques are also susceptible to shadows and specularities caused by different lighting conditions during different times of the day. An interesting research direction is to study whether other sensors such as NIR~\cite{bachmann2013micro} and thermal cameras~\cite{vadivambal2011applications} or their combinations can improve detection accuracy irrespective of lighting condition. Other interesting research directions for the future include grading fruit by color/maturity, measuring the sugar content in the fruit and detect existing and potential diseases.


Chapter~\ref{chapter:fruit_counting} presented a method for counting fruit from segmented images using unsupervised shape-based clustering. This approach assumes that the fruit is ellipsoidal which is not the case for some fruit such as bananas. The method struggles to predict the correct number of fruit in the presence of significant occlusions ($80\%- 90\%$). A deep learning approach proposed by  H{\"a}ni et al.~\cite{hani_jfr_counting}, suffers from similar problems. A potential research direction is to learn specific occluding patterns typical to different varieties of fruit to determine the accurate fruit count. Currently, the deep learning approach is not capable of measuring the fruit size. The clustering approach can only provide fruit size estimates for fruit with an ellipsoidal shape. An obvious research question is how to extend these approaches to capture size information for fruit with arbitrary shapes (e.g. bananas). 


Chapter~\ref{chapter:sfm} presented a method that can recover the underlying scene geometry and camera motion using detected fruit as features. In essence, the success of this approach can be attributed to using objects which are relatively stable in the presence of wind. Therefore, besides fruit tree trunks and thick branches can also be used as sources of reliable feature points. The approach though does not associate scale and orientation preserving descriptors to the features making it impossible to match them explicitly without chaining across consecutive frames. An interesting research direction is to associate such descriptors to these features and study their effectiveness for visual Simultaneous Localization and Mapping (SLAM~\cite{mur2017orb} scenarios (e.g how effective these features are for loop closure). 


In Chapter~\ref{chapter:merge_both}, we developed a method for merging reconstructions from two sides of a tree row using occlusion boundaries from orthographic views and semantic information (i.e., detected trunks and local grounds). The method assumed the existence of a singular ground plane which is not realistic for hilly/mountainous terrains. An immediate extension to the work is to replace the singular ground plane assumption with a combination of planes. The presented method performed trunk detection based on filtering 3D points. This process is not robust and in the extended version of the work presented in Dong et al.~\cite{dong2018semantic}, we replaced this technique with Mask R-CNN~\cite{he2017mask}. Other interesting research directions include merging the side view reconstructions with top view reconstruction~\cite{PengI17} to obtain a complete 3D map of the environment.

In Chapter~\ref{chapter:map_yield}, we integrated previously presented solutions for fruit detection, counting and reconstruction techniques to obtain aggregate fruit count. The techniques presented in this chapter included tracking fruit from a single side, eliminating fruit visible from both sides, and removing fruit on the ground and other rows.  The complete system achieved $95.56\% -97.83\%$ yield accuracies outperforming all state-of-the-art systems. The presented system though does not contain an estimator for fruit that is not visible in the captured footage from both sides. An immediate research direction is to study techniques for calibrating the system for occluded fruit. While some preliminary work exists for such calibration~\cite{wang,bargoti_image_2017}, their scalability and generalization capability across different spatial locations and crop varieties have not been investigated. Another interesting future research direction is precise fruit localization and fruit pose estimation. Obtaining precise geometric representation of fruit clusters will add more semantic information to the underlying 3D reconstructions and enable picking robots to plan their trajectories effectively. Fruit such as apples, oranges, peaches, etc. can be represented by regular geometric surfaces such as ellipsoids, spheres, etc. Such surfaces can be reconstructed from their projection boundaries in three or more views. Therefore, it is possible to recover the geometric representation of fruit clusters combining the image-based counting methods with estimated camera poses. Additionally, it is worth investigating whether such representations can be learned directly from multiple consecutive views using recurrent neural networks~\cite{zaremba2014recurrent}.

In chapter~\ref{chapter:active_counting}, we studied a view planning problem where a manipulator is charged with accurate fruit counting. We presented a method for eliminating combinatorially redundant world models and designed single and multi-step planners based on this representation. The presented approach updated the posterior probabilities associated with every world model in consideration but did not update the actual models themselves. Therefore, despite converging to the correct count it did not recover the fruit poses. Future work would be to update the physical models after each additional view to recovering the precise geometric model of the cluster. Another interesting research direction is to extend the strategy for different types of fruit. For example, strawberries and raspberries do not form large clusters but the space between individual fruit/ fruit cluster is very small. Therefore, inter-cluster views are going to be far more effective than intra-cluster views. On the other hand, blueberries often form large clusters and our intra-cluster view planning is going to be more effective in that case.


In Chapter~\ref{chapter:semgan}, we presented an adversarial framework for image to image translation along with the underlying semantics. The proposed network achieved improved results in object transfiguration tasks involving significant geometric changes (e.g circle $\to$ triangle, sheep $\to$ giraffe, etc). It was able to preserve the semantic boundaries and the details in the background better compared to state-of-the-art methods~\cite{zhu_unpaired_2017,mo_instance-aware_2019}. In the domain translation experiments, the network was able to preserve the underlying semantic labels and reduced visual artifacts. The method struggles to preserve color and texture for overlapping instances. An immediate extension, therefore, is to study ways to incorporate instance level information. Future work would also include extending the current framework to perform domain transfer without semantic labels from the target domain. In terms of the loss function, interesting research directions include investigating the effectiveness of the Wasserstein distance-based loss~\cite{shen_wasserstein_2017}, exploring the effect of first and second-order idempotency~\cite{ostyakov2018seigan} beyond identity loss.



\section{Future Research Directions}
This dissertation focused on developing practical computer vision, machine learning, and planning algorithms to advance the state-of-the-art for integrated specialty farm management. Some of these techniques are now in the process of being commercialized. Going forward, as farms become more uniform and mechanized, we predict the following precision farming issues will emerge and present interesting extensions to our techniques.

\subsection{Long Term Monitoring}
Precision agriculture relies on high resolution spatial and temporal data to build integrated decision support systems. Future farms are likely to capture both data streams to promote autonomy. From the temporal side, data will be collected at every stage of the crop's life. Extracting necessary information from such data will pose numerous challenges spanning detection, planning, and coverage. The developed detection techniques in this thesis will need to be extended to handle flowers and fruitlet. Detecting fruitlets will require more resolution than mature fruit. An important problem here is to identify coverage patterns most effective for close up imaging.

Another interesting research direction is to develop temporal growth models for fruit from different rootstocks. With a sufficient amount of data, it might be possible to learn and predict the entire lifecycle of the fruit: flower $\to$ fruitlet $\to$mature fruit. It requires resolving many challenges though, such as what type of data to use, what kind of representation to use for different stages and so on. Other interesting research directions include correlating final yield with different fruitlet/ flower count, learning the growth rate of the fruit, learning the change in fruit color over time and so on.

\subsection{Multi-level Spatial Semantic Maps}
Future orchards are likely to be more uniform in terms of canopy size, rootstock, and yield. Collecting spatial data, analyzing variability and taking required actions to reduce them is key to achieving uniformity. In terms of images, spatial data in orchards are collected at three different levels. At the high level, there are images from satellites and drones capturing data at coarse resolution.  At the middle level, images are collected from within the rows using handheld devices, Unmanned Aerial Vehicles (UAVs) and ground robots. At the lower level, we have close up images from manipulators and handheld devices. In this dissertation, we mainly focused on the middle level and recovered useful semantics such as fruit, tree trunk, and ground planes. An interesting research direction is to recover more underlying semantics at each level and register them. For example, an interesting research problem is to develop methods to register a reconstruction from top-view images obtained from drones to side view reconstructions. From the spatial perspective, the ultimate goal is to build a Google map type system from which can answer queries such as fruit count at a particular row, trees with low fruit counts, etc.


\subsection{Autonomous Picking}
Picking is the most labor-intensive job for orchards. There are several academic and commercial initiatives~\cite{silwal2017design,xiong2018design,abundant} for developing robots for picking apples, strawberries, etc. Currently, the main technical challenges for picker robots are sensing and manipulation. For example, an apple-picking robot has to first identify apples ready to be picked. Some of these apples could be hidden behind the immature fruit. Therefore, it needs to plan a trajectory and grasp without hurting immature fruit. Strawberry picking robots on the other hand face challenging manipulation problems. Ripe strawberries must be picked without bruising their softening shoulders and they have to be placed delicately in clear clam-shell.

While the main focus of this dissertation is yield mapping, many of the developed modules can be useful for picking as well. For example, an interesting extension to the deep network for detection is to predict ripeness. The reconstruction methods presented in Chapter~\ref{chapter:sfm} and \ref{chapter:merge_both} together with detection can provide tentative locations of ripe fruit. Utilizing, this picker robots can plan their picking order and trajectories. For planning a grasp though, the robot has to find the fruit size, location, and orientation precisely. To get this information, they can use an interesting extension to the view planning approach~\ref{chapter:active_counting} by incorporating trajectory length in the cost function and recovering the precise geometric model of the fruit cluster. 


\section{Concluding Remarks}
This is a great time for autonomy in specialty farms. New technologies are emerging every day to solve delicate farming tasks and taking us closer toward complete autonomy. Several technical challenges remain to be solved before we reach that point though. In this dissertation, we developed practical solutions to tackle one of these challenges. We hope that this surge of building intelligent autonomous solutions for specialty farms continues and helps our oldest industry - agriculture,  to be better prepared than ever to feed the evergrowing population.